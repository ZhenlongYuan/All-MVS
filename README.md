# All-MVS (Methods and Datasets)

> Contributions welcomed!
>
> Benchmark [Benchmark](#Benchmark)
>
> 
> Traditional [2024](#2024-1) | [2023](#2023-1) | [2022](#2022-1) | [2021](#2021-1) | [2020](#2020-1) | [2019](#2019-1) | [2018](#2018-1) | [Early](#early)
> 
> Learning-based [2024](#2024) | [2023](#2023) | [2022](#2022) | [2021](#2021) | [2020](#2020) | [2019](#2019) | [2018](#2018) | [2017](#2017)

### Benchmark

+ **DTU** [CVPR2014, IJCV2016]
  + Large-scale data for multiple-view stereopsis [paper: [CVPR2014](https://roboimagedata2.compute.dtu.dk/data/text/multiViewCVPR2014.pdf), [IJCV2016](https://link.springer.com/content/pdf/10.1007/s11263-016-0902-9.pdf)] [[website](http://roboimagedata.compute.dtu.dk/?page_id=36)] [[Eval code](https://github.com/Todd-Qi/MVSNet-PyTorch/tree/master/evaluations/dtu)] [[video](https://www.bilibili.com/video/BV1k5411G7NA/)]

+ **Tanks and Temples** [ACM ToG2017]
  + Tanks and Temples: Benchmarking Large-Scale Scene Reconstruction  [[paper](https://docs.google.com/uc?export=download&id=0B-ePgl6HF260bGJkdFBCemRLZGM)] [[supp](https://docs.google.com/uc?export=download&id=0B-ePgl6HF260MGhQX0dCcmdHbFk)] [[website](https://www.tanksandtemples.org/)] [[Github](https://github.com/intel-isl/TanksAndTemples)] [[leaderboard](https://www.tanksandtemples.org/leaderboard/)]

+ **ETH3D** [CVPR2017]
  + A Multi-View Stereo Benchmark with High-Resolution Images and Multi-Camera Videos [[paper](https://www.eth3d.net/data/schoeps2017cvpr.pdf)] [[supp](https://www.eth3d.net/data/schoeps2017cvpr-supp.pdf)] [[website](https://www.eth3d.net/)] [[Github](https://github.com/ETH3D)]

+ **BlendedMVS** [CVPR2020]
  + BlendedMVS: A Large-Scale Dataset for Generalized Multi-View Stereo Network [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yao_BlendedMVS_A_Large-Scale_Dataset_for_Generalized_Multi-View_Stereo_Networks_CVPR_2020_paper.pdf)] [[supp](https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Yao_BlendedMVS_A_Large-Scale_CVPR_2020_supplemental.pdf)] [[Github](https://github.com/YoYo000/BlendedMVS)] [[visual](https://github.com/kwea123/BlendedMVS_scenes)] 

+ **Strecha** [CVPR2008]
  + On Benchmarking Camera Calibration and Multi-View Stereo for High Resolution Imagery [[paper](https://infoscience.epfl.ch/record/126393)] [[website](https://www.epfl.ch/labs/cvlab/data/data-strechamvs/)]

+ **Middlebury** [CVPR2006]
  + A Comparison and Evaluation of Multi-View Stereo Reconstruction Algorithms [[paper](https://vision.middlebury.edu/mview/seitz_mview_cvpr06.pdf)] [[website](https://vision.middlebury.edu/mview/)]
 
+ **GigaMVS** [T-PAMI2021]
  + GigaMVS: A Benchmark for Ultra-large-scale Gigapixel-level 3D Reconstruction [[paper](https://ieeexplore.ieee.org/document/9547729)] [[website](http://www.gigamvs.com/)]

+ **Multi-sensor large-scale dataset for multi-view 3D reconstruction** [CVPR2023]
  + Multi-sensor large-scale dataset for multi-view 3D reconstruction [[paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Voynov_Multi-Sensor_Large-Scale_Dataset_for_Multi-View_3D_Reconstruction_CVPR_2023_paper.pdf)] [[website](https://skoltech3d.appliedai.tech/)]

## Learning-based MVS Methods

### 2024

+ **GoMVS** [CVPR2024]
  + GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo [[Paper](https://arxiv.org/abs/2404.07992)] [[GitHub](https://github.com/Wuuu3511/GoMVS)] [[Webpage](https://wuuu3511.github.io/gomvs/)]

+ **AC-MVSNet** [ICCECT2024]
  + Multi-View Stereo Reconstruction Based on Adaptive Aggregation and Coordinate Attention Mechanism [[Paper](https://ieeexplore.ieee.org/abstract/document/10546032)] 

+ **CT-MVSNet** [MMM2024]
  + Efficient Multi-View Stereo with Cross-scale Transformer [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-53308-2_29)] [[GitHub](https://github.com/wscstrive/CT-MVSNet)]

+ **FDN-MVS** [The_Visual_Computer2024]
  + Feature Distribution Normalization Network for Multi-View Stereo [[Paper](https://link.springer.com/article/10.1007/s00371-024-03334-1)] [[GitHub](https://github.com/ZYangChen/FDN-MVS)]

+ **MVSFormer++** [ICLR2024]
  + MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo [[Paper](https://openreview.net/forum?id=wXWfvSpYHh)] [[GitHub](https://github.com/maybeLx/MVSFormerPlusPlus)]
  
+ **RobustMVS** [TCSVT2024]
  + RobustMVS: Single Domain Generalized Deep Multi-view Stereo [[Paper](https://ieeexplore.ieee.org/abstract/document/10528330)] [[GitHub](https://github.com/ToughStoneX/Robust-MVS)]

+ **CT-MVSNet** [MTA2024]
  + CT-MVSNet: Curvature-Guided Multi-View Stereo with Transformers [[Paper](https://link.springer.com/article/10.1007/s11042-024-19227-3)]
 [[GitHub](https://github.com/Sun-Licheng/CT-MVSNet)]

+ **DS-PMNet** [AAAI2024]
  + Learning Deformable Hypothesis Sampling for Accurate PatchMatch[[Paper](https://arxiv.org/abs/2312.15970)][[GitHub](https://github.com/Geo-Tell/DS-PMNet)]
 
+ **HAMMER** [WACV2024]
  + HAMMER: Learning Entropy Maps to Create Accurate 3D Models in Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Weilharter_HAMMER_Learning_Entropy_Maps_To_Create_Accurate_3D_Models_in_WACV_2024_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/WACV2024/supplemental/Weilharter_HAMMER_Learning_Entropy_WACV_2024_supplemental.pdf)]

+ **GC-MVSNet** []
  +  GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Vats_GC-MVSNet_Multi-View_Multi-Scale_Geometrically-Consistent_Multi-View_Stereo_WACV_2024_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/WACV2024/supplemental/Vats_GC-MVSNet_Multi-View_Multi-Scale_WACV_2024_supplemental.pdf)] 
[[GitHub](https://github.com/vkvats/GC-MVSNet)]

### 2023

+ **SDA-MVS** [ACMMM2023]
  + Semi-supervised Deep Multi-view Stereo [[Paper](https://dl.acm.org/doi/10.1145/3581783.3611931)]

+ **S-OmniMVS** [ACMMM2023]
  +  S-OmniMVS: Incorporating Sphere Geometry into Omnidirectional Stereo Matching [[Paper](https://dl.acm.org/doi/10.1145/3581783.3612381)]

+ **ET-MVSNet** [ICCV2023]
  +  When Epipolar Constraint Meets Non-Local Operators in Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_When_Epipolar_Constraint_ICCV_2023_supplemental.pdf)] [[GitHub](https://github.com/TQTQliu/ET-MVSNet)]

+ **CL-MVSNet** [ICCV2023]
  + CL-MVSNet: Unsupervised Multi-View Stereo with Dual-Level Contrastive Learning [[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_supplemental.pdf)][[GitHub](https://github.com/KaiqiangXiong/CL-MVSNet)]

+ **DMVSNet** [ICCV2023]
  + Constraining Depth Map Geometry for Multi-View Stereo: A Dual-Depth Approach with Saddle-shaped Depth Cells [[Paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ye_Constraining_Depth_Map_ICCV_2023_supplemental.pdf) [[Paper](https://arxiv.org/abs/2307.09160)] [[GitHub](https://github.com/DIVE128/DMVSNet)]

+ **Bi-ClueMVSNet** [IJCNN2023]
  + Bi-ClueMVSNet: Learning Bidirectional Occlusion Clues for Multi-View Stereo [[Paper](https://ieeexplore.ieee.org/abstract/document/10191325)]

+ **Costformer** [IJCAI2023]
  +  Costformer: Cost Transformer for Cost Aggregation in Multi-View Stereo [[Paper](https://arxiv.org/abs/2305.10320)]
 [[GitHub](https://github.com/xmjtt/costformer)]

+ **PA-PointMVSNet** [Applied_Intelligence2023]
  +  Multi‑View Stereo Network With Point Attention[[Paper](https://link.springer.com/article/10.1007/s10489-023-04806-y)]

+ **Edge-Aware Spatial Propagation Network for Multi-view Depth Estimation** [NPL2023]
  +  Edge-Aware Spatial Propagation Network for Multi-view Depth Estimation [[Paper](https://link.springer.com/article/10.1007/s11063-023-11356-4)]

+ **AP-UCSNet** [Applied_Intelligence2023]
  +  Uncertainty Awareness With Adaptive Propagation for Multi-View Stereo [[Paper](https://link.springer.com/article/10.1007/s10489-023-04910-z)]

+ **AdaptMVSNet** [CG2023]
  +  AdaptMVSNet: Efficient Multi-View Stereo With Adaptive Convolution and Attention Fusion [[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0097849323001838)]

+ **Adaptive Region Aggregation for Multi-View Stereo Matching Using Deformable Convolutional Networks** [The_Photogrammetric_Record2023]
  +  Adaptive Region Aggregation for Multi-View Stereo Matching Using Deformable Convolutional Networks [[Paper](https://onlinelibrary.wiley.com/doi/epdf/10.1111/phor.12459)]

+ **RepC-MVSNet** [Agronomy2023]
  +  RepC-MVSNet: A Reparameterized Self-Supervised 3D Reconstruction Algorithm for Wheat 3D Reconstruction [[Paper](https://www.mdpi.com/2073-4395/13/8/1975)]

+ **ES-MVSNet** [CoRR2023]
  + ES-MVSNet: Efficient Framework for End-to-end Self-supervised Multi-View Stereo[[Paper](https://arxiv.org/abs/2308.02191)]

+ **ARAI-MVSNet** [PR2023]
  + ARAI-MVSNet: A Multi-View Stereo Depth Estimation Network With Adaptive Depth Range and Depth Interval [[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320323005836)] [[GitHub](https://github.com/zs670980918/ARAI-MVSNet)]

+ **DSC-MVSNet** [Complex_Intelligent_Systems2023]
  + DSC-MVSNet: Attention Aware Cost Volume Regularization Based on Depthwise Separable Convolution for Multi-View Stereo [[Paper](https://link.springer.com/article/10.1007/s40747-023-01106-3)] [[GitHub](https://github.com/zs670980918/DSC-MVSNet)]

+ **NR-MVSNet** [TIP2023]
  + NR-MVSNet: Learning Multi-View Stereo Based on Normal Consistency and Depth Refinement [[Paper](https://ieeexplore.ieee.org/abstract/document/10120723)] [[GitHub](https://github.com/wdkyh/NR-MVSNet)]

+ **PT-MVSNet** [CVIDL2023]
  + PT-MVSNet: Overlapping Attention Multi-view Stereo Network with Transformers [[Paper](https://ieeexplore.ieee.org/abstract/document/10167367)]

+ **GDINet** [IEEE--Access2023]
  +  Multi-View Stereo Network With Gaussian Distribution Iteration[[Paper](https://ieeexplore.ieee.org/document/10138389)]

+ **A-SATMVSNet** [FES2023]
  + A-SATMVSNet: An Attention-Aware Multi-View Stereo Matching Network Based on Satellite Imagery [[Paper](https://www.frontiersin.org/articles/10.3389/feart.2023.1108403/full)]

+ **GeoMVSNet** [CVPR2023]
  + GeoMVSNet: Learning Multi-View Stereo with Geometry Perception [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_GeoMVSNet_Learning_Multi-View_Stereo_With_Geometry_Perception_CVPR_2023_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_GeoMVSNet_Learning_Multi-View_CVPR_2023_supplemental.pdf)]
 [[GitHub](https://github.com/doubleZ0108/GeoMVSNet)] [[Video](https://www.youtube.com/watch?v=XqLDgJAZAKc)]

+ **RA-MVSNet** [CVPR2023]
  +  Multi-View Stereo Representation Revisit: Region-Aware MVSNet [[Paper](https://arxiv.org/abs/2304.13614)]

+ **RIAV-MVS** [CVPR2023]
  +  RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo [[Paper](https://arxiv.org/abs/2205.14320)]

+ **IGEV-MVS** [CVPR2023]
  +  Iterative Geometry Encoding Volume for Stereo Matching [[Paper](https://arxiv.org/abs/2303.06615)] [[GitHub](https://github.com/gangweiX/IGEV)]


+ **N2MVSNet** [ICASSP2023]
  + N2MVSNet: Non-Local Neighbors Aware Multi-View Stereo Network [[Paper](https://ieeexplore.ieee.org/document/10095299)]

+ **ContextMVS** [MMM2023]
  +  Context-Guided Multi-View Stereo with Depth Back-Projection [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-27818-1_8)]

+ **Un-OmniMVS** [CoRR2023]
  +  Unsupervised OmniMVS: Efficient Omnidirectional Depth Inference via Establishing Pseudo-Stereo Supervision [[Paper](https://arxiv.org/abs/2302.09922)]
 [[GitHub](https://github.com/Chen-z-s/Un-OmniMVS)]

+ **MG-MVSNet** [Neurocomputing2023]
  +  MG-MVSNet: Multiple Granularities Feature Fusion Network for Multi-View Stereo [[Paper](https://www.sciencedirect.com/science/article/pii/S092523122300070X)]

+ **FFP-MVSNet** [CSPS2023]
  +  FFP-MVSNet: Feature Fusion Based Patchmatch for Multi-View Stereo [[Paper](https://link.springer.com/chapter/10.1007/978-981-99-1260-5_21)]

+ **MosaicMVS** [TMM2023]
  +  MosaicMVS: Mosaic-based Omnidirectional Multi-View Stereo for Indoor Scenes [[Paper](https://ieeexplore.ieee.org/document/10005048)] [[GitHub](https://github.com/min-jung-shin/MosaicMVS)]

+ **DELS-MVS** [WACV2023]
  + DELS-MVS: Deep Epipolar Line Search for Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Sormann_DELS-MVS_Deep_Epipolar_Line_Search_for_Multi-View_Stereo_WACV_2023_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/WACV2023/supplemental/Sormann_DELS-MVS_Deep_Epipolar_WACV_2023_supplemental.pdf)] [[Paper](https://arxiv.org/abs/2212.06626)]

+ **360MVSNet** [WACV2023]
  +  360MVSNet: Deep Multi-View Stereo Network with 360◦ Images for Indoor Scene Reconstruction [[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Chiu_360MVSNet_Deep_Multi-View_Stereo_Network_With_360deg_Images_for_Indoor_WACV_2023_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/WACV2023/supplemental/Chiu_360MVSNet_Deep_Multi-View_WACV_2023_supplemental.pdf)][[Webpage](https://jdily.github.io/proj_site/360mvsnet_proj.html)]

+ **nLMVS-Net** [WACV2023]
  +  nLMVS-Net: Deep Non-Lambertian Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Yamashita_nLMVS-Net_Deep_Non-Lambertian_Multi-View_Stereo_WACV_2023_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/WACV2023/supplemental/Yamashita_nLMVS-Net_Deep_Non-Lambertian_WACV_2023_supplemental.zip)] [[Paper](https://arxiv.org/abs/2207.11876)][[Webpage](https://vision.ist.i.kyoto-u.ac.jp/)]

+ **EPNet** [AAAI2023]
  +  Efﬁcient Edge-Preserving Multi-View Stereo Network for Depth Estimation [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/25330)] [[GitHub](https://github.com/susuwj/EPNet)]

+ **DispMVS** [AAAI2023]
  + Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity [[Paper](https://arxiv.org/abs/2211.16905)][[GitHub](https://github.com/Yannnnnnnnnnnn/DispMVS_release)]

+ **MVSFormer** [TMLR2023]
  +  MVSFormer: Multi-View Stereo with Pre-trained Vision Transformers and Temperature-based Depth [[Paper](https://arxiv.org/abs/2208.02541)][[GitHub](https://github.com/ewrfcas/MVSFormer)]

### 2022

+ **GigaMVS** [TPAMI2022]
  +  GigaMVS: A Benchmark for Ultra-Large-Scale Gigapixel-Level 3D Reconstruction [[Paper](https://ieeexplore.ieee.org/abstract/document/9547729)]
 [[GitHub](https://github.com/THU-luvision/GigaMVS)] [[Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](https://gigavision.cn/data/news/?nav=GigaMVS%20RAWDATA)]

+ **Multistage Pixel-Visibility Learning With Cost Regularization for Multiview Stereo** [TASE2022]
  +  Multistage Pixel-Visibility Learning With Cost Regularization for Multiview Stereo [[Paper](https://ieeexplore.ieee.org/abstract/document/9761790)]

+ **Global Contextual Complementary Network for Multi-View Stereo** [BMVC2022]
  + Global Contextual Complementary Network for Multi-View Stereo [[Paper](https://bmvc2022.mpi-inf.mpg.de/0919.pdf) [[Supp](https://bmvc2022.mpi-inf.mpg.de/0919_poster.pdf)][[Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](https://bmvc2022.mpi-inf.mpg.de/919/)]

+ **HR-MVSNet** [BMVC2022]
  +  Hybrid Cost Volume Regularization for Memory-efficient Multi-View Stereo Networks [[Paper](https://bmvc2022.mpi-inf.mpg.de/0073.pdf)] [[Supp](https://bmvc2022.mpi-inf.mpg.de/0073_poster.pdf)] [[Webpage](https://img.shields.io/badge/Project-Page-3cba54?style=flat&logo=Google%20chrome&logoColor=white)](https://bmvc2022.mpi-inf.mpg.de/73/)]

+ **SPGNet** [CG2022]
  +  Sparse Prior Guided Deep Multi-View Stereo [[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0097849322001157)]

+ **UGNet** [TCVST2022]
  +  Uncertainty-guided Multi-View Stereo Network for Depth Estimation [[Paper](https://ieeexplore.ieee.org/abstract/document/9797764/)]

+ **BDE-MVSNet** [ACCV2022]
  +  Adaptive Range guided Multi-View Depth Estimation with Normal Ranking Loss [[Paper](https://openaccess.thecvf.com/content/ACCV2022/papers/Ding_Adaptive_Range_guided_Multi-view_Depth_Estimation_with_Normal_Ranking_Loss_ACCV_2022_paper.pdf)]

+ **ElasticMVS** [NIPS2022]
  +  ElasticMVS: Learning Elastic Part Representation for Self-Supervised Multi-View Stereopsis [[Paper](https://openreview.net/forum?id=lAN7mytwrIy)] [[Supp](https://openreview.net/attachment?id=lAN7mytwrIy&name=supplementary_material)]

+ **WT-MVSNet** [NIPS2022]
  +  WT-MVSNet: Window-based Transformers for Multi-View Stereo [[Paper](https://openreview.net/forum?id=EeCdsAj80Wr)] [[Supp](https://openreview.net/attachment?id=EeCdsAj80Wr&name=supplementary_material)]

+ **Guided-MVS** [IROS2022]
  + Multi-View Guided Multi-View Stereo [[Paper](https://arxiv.org/abs/2210.11467)] [[GitHub](https://github.com/andreaconti/multi-view-guided-multi-view-stereo)]

+ **ParseMVS** [ACMMM2022]
  + ParseMVS: Learning Primitive-aware Surface Representations for Sparse Multi-View Stereopsis [[Paper](https://dl.acm.org/doi/abs/10.1145/3503161.3547920)] [[Supp](https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3547920&file=MM22-fp0726.mp4)]

+ **Self-Supervised Multi-View Stereo via Adjacent Geometry Guided Volume Completion** [ACMMM2022]
  +  Self-Supervised Multi-View Stereo via Adjacent Geometry Guided Volume Completion [[Paper](https://dl.acm.org/doi/10.1145/3503161.3547926)] [[Supp](https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3547926&file=MM22-fp0750.mp4)]

+ **Self-supervised Multi-View Stereo via Inter and Intra Network Pseudo Depth** [ACMMM2022]
  +  Self-supervised Multi-View Stereo via Inter and Intra Network Pseudo Depth [[Paper](https://dl.acm.org/doi/abs/10.1145/3503161.3548212)] [[Supp](https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3548212&file=MM22-fp1890.mp4)]

+ **Deep PatchMatch MVS with Learned Patch Coplanarity, Geometric Consistency and Adaptive Pixel Sampling** [CoRR2022]
  +  Deep PatchMatch MVS with Learned Patch Coplanarity, Geometric Consistency and Adaptive Pixel Sampling [[Paper](https://arxiv.org/abs/2210.07582)]

+ **PSP-MVSNet** [ICANN2022]
  + PSP-MVSNet: Deep Patch-Based Similarity Perceptual for Multi-View Stereo Depth Inference  [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-15919-0_27)]

+ **End-to-End Multi-View Structure-from-Motion with Hypercorrelation Volumes** [SPSIS2022]
  +  End-to-End Multi-View Structure-from-Motion with Hypercorrelation Volumes [[Paper](https://arxiv.org/abs/2209.06926)]

+ **A Benchmark and a Baseline for Robust Multi-View Depth Estimation** [3DV2022]
  +  A Benchmark and a Baseline for Robust Multi-View Depth Estimation [[Paper](https://arxiv.org/abs/2209.06681)][[GitHub](https://github.com/lmb-freiburg/robustmvd)]

+ **MSCVP-MVSNet** [CGI2022]
  +  Cost Volume Pyramid Network with Multi-strategies Range Searching for Multi-View Stereo [[Paper](https://arxiv.org/abs/2207.12032)]
 [[GitHub](https://github.com/SibylGao/MSCVP-MVSNet)]

+ **ATLAS-MVSNet** [ICPR2022]
  +  ATLAS-MVSNet: Attention Layers for Feature Extraction and Cost Volume Regularization in Multi-View Stereo [[GitHub](https://github.com/rafael-weilharter/ATLAS-MVSNet)][[Video](https://www.youtube.com/watch?v=ZLKGKlTloAI)]

+ **DS-MVSNet** [ACMMM2022]
  + DS-MVSNet: Unsupervised Multi-View Stereo via Depth Synthesis [[Paper](https://arxiv.org/abs/2208.06674)][[GitHub](https://github.com/wdkyh/DS-MVSNet)]

+ **IS-MVSNet** [ECCV2022]
  + IS-MVSNet: Importance-sampling-based MVSNet [[Paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136920663.pdf)][[GitHub](https://github.com/NoOneUST/IS-MVSNet)]

+ **KD-MVS** [ECCV2022]
  + KD-MVS: Knowledge Distillation Based Self-supervised Learning for Multi-View Stereo [[Paper](https://arxiv.org/abs/2207.10425)][[GitHub](https://github.com/megvii-research/KD-MVS)][[Webpage](https://dingyikang.github.io/kdmvs.github.io)]

+ **Semi-supervised Deep Multi-View Stereo** [CoRR2022]
  + Semi-supervised Deep Multi-View Stereo [[Paper](https://arxiv.org/abs/2207.11699)]

+ **Miper-MVS** [IS2022]
  +  Miper-MVS: Multi-Scale Itearative Probability Estimation with Refinement for Efficient Multi-View Stereo [[Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4176484)][[GitHub](https://github.com/zhz120/Miper-MVS)]

+ **RC-MVSNet** [ECCV2022]
  +  RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering [[Paper](https://arxiv.org/abs/2203.03949)][[GitHub](https://github.com/Boese0601/RC-MVSNet)] [[Webpage](https://boese0601.github.io/rc-mvsnet)]

+ **Enhancing Multi-View Stereo with Contrastive Matching and Weighted Focal Loss** [ICIP2022]
  +  Enhancing Multi-View Stereo with Contrastive Matching and Weighted Focal Loss [[Paper](https://arxiv.org/abs/2206.10360)]

+ **MVSTER** [ECCV2022]
  +  MVSTER: Epipolar Transformer for Efficient Multi-View Stereo [[Paper](https://arxiv.org/abs/2204.07346)][[GitHub](https://github.com/JeffWang987/MVSTER)]

+ **CER-MVS** [ECCV2022]
  +  Multiview Stereo with Cascaded Epipolar RAFT [[Paper](https://arxiv.org/abs/2205.04502)][[GitHub](https://github.com/princeton-vl/CER-MVS)]

+ **Geo-Neus** [CoRR2022]
  + Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-View Reconstruction [[Paper](https://arxiv.org/abs/2205.15848)]

+ **BH-MVSNet** [TVCG2022]
  +  Bidirectional Hybrid LSTM Based Recurrent Neural Network for Multi-View Stereo [[Paper](https://ieeexplore.ieee.org/abstract/document/9754239)]

+ **Exploiting Correspondences with All-pairs Correlations for Multi-View Depth Estimation** [CoRR2022]
  +  Exploiting Correspondences with All-pairs Correlations for Multi-View Depth Estimation [[Paper](https://arxiv.org/abs/2205.02481)]

+ **MVSTER** [CoRR2022]
  +  Multi-View Stereo with Transformer [[Paper](https://arxiv.org/abs/2112.00336)]

+ **MVS-T** [Sensors2022]
  +  MVS-T: A Coarse-to-Fine Multi-View Stereo Network with Transformer for Low-Resolution Images 3D Reconstruction [[Paper](https://www.mdpi.com/1424-8220/22/19/7659)]

+ **Effi-MVS** [CVPR2022]
  +  Efficient Multi-View Stereo by Iterative Dynamic Cost Volume [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Efficient_Multi-View_Stereo_by_Iterative_Dynamic_Cost_Volume_CVPR_2022_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_Efficient_Multi-View_Stereo_CVPR_2022_supplemental.pdf)][[GitHub](https://github.com/bdwsq1996/Effi-MVS)]

+ **NP-CVP-MVS** [CVPR2022]
  + Non-parametric Depth Distribution Modelling based Depth Inference for Multi-View Stereo [[Paper](https://arxiv.org/abs/2205.03783)][[GitHub](https://github.com/NVlabs/NP-CVP-MVSNet)]

+ **GBi-Net** [CVPR2022]
  +  Generalized Binary Search Network for Highly-Efficient Multi-View Stereo [[Paper](https://arxiv.org/abs/2112.02338)][[GitHub](https://github.com/MiZhenxing/GBi-Net)]

+ **UniMVSNet** [CVPR2022]
  +  Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation and Focal Loss [[Paper](https://arxiv.org/abs/2201.01501)][[GitHub](https://github.com/prstrive/UniMVSNet)]

+ **TransMVSNet** [CVPR2022]
  +  TransMVSNet: Global Context-aware Multi-View Stereo Network with Transformers [[Paper](https://arxiv.org/abs/2111.14600)][[GitHub](https://github.com/MegviiRobot/TransMVSNet)]

+ **IterMVS** [CVPR2022]
  +  IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_IterMVS_Iterative_Probability_Estimation_for_Efficient_Multi-View_Stereo_CVPR_2022_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Wang_IterMVS_Iterative_Probability_CVPR_2022_supplemental.pdf)] [[GitHub](https://github.com/FangjinhuaWang/IterMVS)]

+ **MaGNet** [CVPR2022]
  +  Multi-View Depth Estimation by Fusing Single-View Depth Probability with Multi-View Geometry [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Bae_Multi-View_Depth_Estimation_by_Fusing_Single-View_Depth_Probability_With_Multi-View_CVPR_2022_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Bae_Multi-View_Depth_Estimation_CVPR_2022_supplemental.pdf) [[Paper](http://arxiv.org/abs/2112.08177)][[GitHub](https://github.com/baegwangbin/MaGNet)]

+ **CDS-MVSNet** [ICLR2022]
  +  Curvature-guided dynamic scale networks for Multi-View Stereo [[Paper](https://openreview.net/pdf?id=_Wzj0J2xs2D) [[Supp](https://openreview.net/attachment?id=_Wzj0J2xs2D&name=supplementary_material)] [[GitHub](https://github.com/TruongKhang/cds-mvsnet)]

+ **DDL-MVS / iMVS** [CoRR2022]
  +  DDL-MVS: Depth Discontinuity Learning for MVS Networks [[Paper](https://arxiv.org/abs/2203.01391)][[GitHub](https://github.com/Mirmix/ddlmvs)]

+ **PlaneMVS** [CVPR2022]
  +  PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_PlaneMVS_3D_Plane_Reconstruction_From_Multi-View_Stereo_CVPR_2022_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_PlaneMVS_3D_Plane_CVPR_2022_supplemental.pdf)]

+ **RayMVSNet** [CVPR2022]
  +  RayMVSNet: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/CVPR2022/papers/Xi_RayMVSNet_Learning_Ray-Based_1D_Implicit_Fields_for_Accurate_Multi-View_Stereo_CVPR_2022_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xi_RayMVSNet_Learning_Ray-Based_CVPR_2022_supplemental.pdf)] [[GitHub](https://github.com/Airobin329/RayMVSNet)]

+ **DRI-MVSNet** [PLoS2022]
  +  DRI-MVSNet: A Depth Residual Inference Network for Multi-View Stereo Images [[Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8942269/pdf/pone.0264721.pdf)]

+ **A Semi‑Supervised Method for PatchMatch Multi‑View Stereo with Sparse Points** [Photonics2022]
  +  A Semi‑Supervised Method for PatchMatch Multi‑View Stereo with Sparse Points [[Paper](https://www.mdpi.com/2304-6732/9/12/983)]

+ **DEMVSNet** [IETCV2022]
  +  DEMVSNet: Denoising and Depth Inference for Unstructured Multi‐view Stereo on Noised Images [[Paper](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/cvi2.12102)]
 
+ **PVSNet** [IJCV2022]
  +  Learning Inverse Depth Regression for Pixelwise Visibility-Aware Multi-View Stereo Networks [[Paper](https://link.springer.com/article/10.1007/s11263-022-01628-2)]

### 2021

+ **Long-range Attention Network for Multi-View Stereo** [WACV2021]
  +  Long-range Attention Network for Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/WACV2021/papers/Zhang_Long-Range_Attention_Network_for_Multi-View_Stereo_WACV_2021_paper.pdf)][[Video](https://www.youtube.com/watch?v=BfwBth3HgQU)]

+ **PatchMVSNet** [CVPR2021]
  + PatchMVSNet: Patch-wise Unsupervised Multi-View Stereo for Weakly-Textured Surface Reconstruction [[Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_PatchmatchNet_Learned_Multi-View_Patchmatch_Stereo_CVPR_2021_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/CVPR2021/supplemental/Wang_PatchmatchNet_Learned_Multi-View_CVPR_2021_supplemental.pdf)] [[GitHub](https://github.com/FangjinhuaWang/PatchmatchNet)]









































