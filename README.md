# All-MVS (Methods and Datasets)

> Contributions welcomed!
>
> Benchmark [Benchmark](#Benchmark)
>
> 
> Traditional [2024](#2024-1) | [2023](#2023-1) | [2022](#2022-1) | [2021](#2021-1) | [2020](#2020-1) | [2019](#2019-1) | [2018](#2018-1) | [Early](#early)
> 
> Learning-based [2024](#2024) | [2023](#2023) | [2022](#2022) | [2021](#2021) | [2020](#2020) | [2019](#2019) | [2018](#2018) | [2017](#2017)

### Benchmark

+ **DTU** [CVPR2014, IJCV2016]
  + Large-scale data for multiple-view stereopsis [paper: [CVPR2014](https://roboimagedata2.compute.dtu.dk/data/text/multiViewCVPR2014.pdf), [IJCV2016](https://link.springer.com/content/pdf/10.1007/s11263-016-0902-9.pdf)] [[website](http://roboimagedata.compute.dtu.dk/?page_id=36)] [[Eval code](https://github.com/Todd-Qi/MVSNet-PyTorch/tree/master/evaluations/dtu)] [[video](https://www.bilibili.com/video/BV1k5411G7NA/)]

+ **Tanks and Temples** [ACM ToG2017]
  + Tanks and Temples: Benchmarking Large-Scale Scene Reconstruction  [[paper](https://docs.google.com/uc?export=download&id=0B-ePgl6HF260bGJkdFBCemRLZGM)] [[supp](https://docs.google.com/uc?export=download&id=0B-ePgl6HF260MGhQX0dCcmdHbFk)] [[website](https://www.tanksandtemples.org/)] [[Github](https://github.com/intel-isl/TanksAndTemples)] [[leaderboard](https://www.tanksandtemples.org/leaderboard/)]

+ **ETH3D** [CVPR2017]
  + A Multi-View Stereo Benchmark with High-Resolution Images and Multi-Camera Videos [[paper](https://www.eth3d.net/data/schoeps2017cvpr.pdf)] [[supp](https://www.eth3d.net/data/schoeps2017cvpr-supp.pdf)] [[website](https://www.eth3d.net/)] [[Github](https://github.com/ETH3D)]

+ **BlendedMVS** [CVPR2020]
  + BlendedMVS: A Large-Scale Dataset for Generalized Multi-View Stereo Network [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yao_BlendedMVS_A_Large-Scale_Dataset_for_Generalized_Multi-View_Stereo_Networks_CVPR_2020_paper.pdf)] [[supp](https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Yao_BlendedMVS_A_Large-Scale_CVPR_2020_supplemental.pdf)] [[Github](https://github.com/YoYo000/BlendedMVS)] [[visual](https://github.com/kwea123/BlendedMVS_scenes)] 

+ **Strecha** [CVPR2008]
  + On Benchmarking Camera Calibration and Multi-View Stereo for High Resolution Imagery [[paper](https://infoscience.epfl.ch/record/126393)] [[website](https://www.epfl.ch/labs/cvlab/data/data-strechamvs/)]

+ **Middlebury** [CVPR2006]
  + A Comparison and Evaluation of Multi-View Stereo Reconstruction Algorithms [[paper](https://vision.middlebury.edu/mview/seitz_mview_cvpr06.pdf)] [[website](https://vision.middlebury.edu/mview/)]
 
+ **GigaMVS** [T-PAMI2021]
  + GigaMVS: A Benchmark for Ultra-large-scale Gigapixel-level 3D Reconstruction [[paper](https://ieeexplore.ieee.org/document/9547729)] [[website](http://www.gigamvs.com/)]

+ **Multi-sensor large-scale dataset for multi-view 3D reconstruction** [CVPR2023]
  + Multi-sensor large-scale dataset for multi-view 3D reconstruction [[paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Voynov_Multi-Sensor_Large-Scale_Dataset_for_Multi-View_3D_Reconstruction_CVPR_2023_paper.pdf)] [[website](https://skoltech3d.appliedai.tech/)]

## Learning-based MVS Methods

### 2024

+ **GoMVS** [CVPR2024]
  + GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo [[Paper](https://arxiv.org/abs/2404.07992)] [[GitHub](https://github.com/Wuuu3511/GoMVS)] [[Webpage](https://wuuu3511.github.io/gomvs/)]

+ **AC-MVSNet** [ICCECT2024]
  + Multi-View Stereo Reconstruction Based on Adaptive Aggregation and Coordinate Attention Mechanism [[Paper](https://ieeexplore.ieee.org/abstract/document/10546032)] 

+ **CT-MVSNet** [MMM2024]
  + Efficient Multi-View Stereo with Cross-scale Transformer [[Paper](https://link.springer.com/chapter/10.1007/978-3-031-53308-2_29)] [[GitHub](https://github.com/wscstrive/CT-MVSNet)]

+ **FDN-MVS** [The_Visual_Computer2024]
  + Feature Distribution Normalization Network for Multi-View Stereo [[Paper](https://link.springer.com/article/10.1007/s00371-024-03334-1)] [[GitHub](https://github.com/ZYangChen/FDN-MVS)]

+ **MVSFormer++** [ICLR2024]
  + MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View Stereo [[Paper](https://openreview.net/forum?id=wXWfvSpYHh)] [[GitHub](https://github.com/maybeLx/MVSFormerPlusPlus)]
  
+ **RobustMVS** [TCSVT2024]
  + RobustMVS: Single Domain Generalized Deep Multi-view Stereo [[Paper](https://ieeexplore.ieee.org/abstract/document/10528330)] [[GitHub](https://github.com/ToughStoneX/Robust-MVS)]

+ **CT-MVSNet** [MTA2024]
  + CT-MVSNet: Curvature-Guided Multi-View Stereo with Transformers [[Paper](https://link.springer.com/article/10.1007/s11042-024-19227-3)]
 [[GitHub](https://github.com/Sun-Licheng/CT-MVSNet)]

+ **DS-PMNet** [AAAI2024]
  + Learning Deformable Hypothesis Sampling for Accurate PatchMatch[[Paper](https://arxiv.org/abs/2312.15970)][[GitHub](https://github.com/Geo-Tell/DS-PMNet)]
 
+ **HAMMER** [WACV2024]
  + HAMMER: Learning Entropy Maps to Create Accurate 3D Models in Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Weilharter_HAMMER_Learning_Entropy_Maps_To_Create_Accurate_3D_Models_in_WACV_2024_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/WACV2024/supplemental/Weilharter_HAMMER_Learning_Entropy_WACV_2024_supplemental.pdf)]

+ **GC-MVSNet** []
  +  GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo [[Paper](https://openaccess.thecvf.com/content/WACV2024/papers/Vats_GC-MVSNet_Multi-View_Multi-Scale_Geometrically-Consistent_Multi-View_Stereo_WACV_2024_paper.pdf)] [[Supp](https://openaccess.thecvf.com/content/WACV2024/supplemental/Vats_GC-MVSNet_Multi-View_Multi-Scale_WACV_2024_supplemental.pdf)] 
[[GitHub](https://github.com/vkvats/GC-MVSNet)]

### 2023











